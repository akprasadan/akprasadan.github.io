---
title: "Research"
format: html
---

This page summarizes some of the recent research I worked on during my PhD, and continue to on the side as I transition toward my postdoctoral research.

## Shape-Constrained Mean Estimation

This topic was the subject of my thesis and combined several themes all at once: mean estimation, minimax optimality, shape-constraints, adversarial contamination, sub-Gaussian noise, and function classes. Let me give a brief overview.

A fundamental problem in statistics is estimating some unknown signal $\mu$ (could be a real number, vector, or function). We are given several noisy observations of the form $Y_i=\mu+\xi_i$ where $\xi_i$ is IID Gaussian noise. At this point, you might propose something like the average $\overline{Y}_i$.

Next, suppose we are told that $\mu$ must belong to a known set $K$. Has the problem become easier? No! Now, we must devise an algorithm that always returns an estimate in this set. This is called shape-constrained estimation.

Moreover, we want an estimate that is *minimax optimal*. This is a very conservative but important benchmark for assessing the performance of an estimator. In this context, we want to produce an estimator whose average performance in the worst-case choice of $\mu$ is minimized. I said 'average' because there is randomness in the data generating process, and worst case because $\mu$ could, in principle, come from anywhere in $K$. In the simple Euclidean vector case, this might be of the form:
$$\inf_{\hat{\mu}} \sup_{\mu \in K} \mathbb{E}\|\hat{\mu} - \mu\|_2^2,$$ where $\hat\mu$ ranges over the set of all estimators.

In this work, we devised minimax optimal techniques to estimate means when the underlying set was *star-shaped* (see below), a generalization of convexity. We extended this work to a non-parametric regression setting, i.e., observing $Y_i=f^{\ast}(X_i)+\xi_i$ and trying to find $f^{\ast}$. We also allowed for adversarial contamination of some fraction $\epsilon<1/2$ of the data. In either case, we generalized our assumptions on $\xi_i$ to permit sub-Gaussian noise.

My advisor, [Matey Neykov](https://mateyneykov.com/), was a co-author on each of the papers and his original 2022 paper on convex-constrained mean estimation continues to spawn interesting research in this field.

![Illustration of a star-shaped set](media/star_shaped_set.png){fig-align="right" width="70%"}

### Selected Publications

- A. Prasadan and M. Neykov. *Characterizing the minimax rate of nonparametric regression under bounded star-shaped constraints*, 2024. [arXiv:2401.07968](https://arxiv.org/abs/2401.07968)
- A. Prasadan and M. Neykov. *Some facts about the optimality of the LSE in the Gaussian sequence model with convex constraint*, 2024. [arXiv:2406.05911](https://arxiv.org/abs/2406.05911)
- A. Prasadan and M. Neykov. *Information theoretic limits of robust sub-Gaussian mean estimation under star-shaped constraints*, 2024. [arXiv:2412.03832](https://arxiv.org/abs/2412.03832)

---

## Multistate and Joint Models

During my PhD, I joined a collaboration between CMU and Novartis to study the use of flexible survival analysis techniques to model the efficacy of immunotherapy for blood cancers. The treatment itself sounds straight out of a sci-fi novel: scientists bioengineer immune cells to modify their own cell structure so the cells can attack cancer cells.

Classic survival analysis can be used to model the literal survival of a subject: the subject is either alive or dead, for example. But what if we wish to capture the dynamic trajectory of patients through different stages of sickness? For example, the patient might first see their condition worsening, then receding, then being fully cancer-free, or maybe reverting to total treatment failure. A *multi-state model* allows us to model a patient's transitions between different states (of cancer), and thus a powerful tool for evaluating cancer treatments.

The second theme of this work was *joint models*, which are a lot more exciting than their generic name suggests. The idea is to jointly model longitudinal and survival processes, when the longitudinal data is endogenous, or internal to the patient. Classic Cox proportional hazard models can handle time varying covariates, but they require exogeneity. This means, for example, that if the patient is censored (e.g., leaves the study or dies), then the existence of the longitudinal covariate should be unaffected. This is true if, for example, your longitudinal variable is the weather. But clearly it fails with biomarkers in your blood. With a joint model, we compute a posterior distribution over the longitudinal and survival processes that gives theoretically valid estimates unlike the regular Cox proportional hazard model.

### Selected Publications

- A. Prasadan et al. *Assessing CAR-T Immunotherapy Outcomes using Multistate Models, Pharmacokinetics, and Tumor Burden*, 2022. *Novartis Technical Report*
