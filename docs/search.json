[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching Experience",
    "section": "",
    "text": "I gained valuable experience as both an instructor and teaching assistant (TA) during my PhD at CMU. I taught the undergraduate Statistical Graphics and Visualization course (36-315) in Summer 2025. I TAed for 11 semesters (listed below), and I was awarded an Outstanding PhD TA Award for the 2024-5 academic year. I also privately tutored a fellow Statistics PhD student in 2021.\nI consider teaching opportunities very important: they force me to learn material I might otherwise skip over and reveal gaps in my own knowledge I didn’t even know existed—the creativity with which students craft questions never ceases to surprise me. Moreover, I built valuable communication skills by working with students whose background ranged from high school to PhD level."
  },
  {
    "objectID": "teaching.html#instructor",
    "href": "teaching.html#instructor",
    "title": "Teaching Experience",
    "section": "Instructor",
    "text": "Instructor\n\n36-315: Statistical Graphics & Visualization\nSummer 2025\nGuest Lecturer, 36-401: Modern Regression\nSpring 2025\nStatistics & Data Science Camp for High-School Students\nSummer 2023"
  },
  {
    "objectID": "teaching.html#teaching-assistant",
    "href": "teaching.html#teaching-assistant",
    "title": "Teaching Experience",
    "section": "Teaching Assistant",
    "text": "Teaching Assistant\n\n36-402: Advanced Methods for Data Analysis\nSpring 2025\n36-700: Probability and Mathematical Statistics\nFall 2024 (Head TA)\nCMU Summer Undergraduate Research Experience (SURE)\nSummer 2023 & Summer 2024 (Head TA in 2024)\n46-929: Financial Time Series Analysis\nSpring 2023 & Spring 2024\n46-927: Machine Learning II\nSpring 2023 & Spring 2024\n36-401: Modern Regression\nFall 2022 & Fall 2023 (Head TA in 2023)\n36-225: Introduction to Probability Theory\nFall 2020"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "A. Prasadan and M. Neykov. Characterizing the minimax rate of nonparametric regression under bounded star-shaped constraints, 2025. arXiv:2401.07968 [math.ST]. To appear in Electronic Journal of Statistics.\n\nA. Prasadan and M. Neykov. Some facts about the optimality of the LSE in the Gaussian sequence model with convex constraint, 2024. arXiv:2406.05911 [math.ST]. Submitted.\n\nA. Prasadan and M. Neykov. Information theoretic limits of robust sub-Gaussian mean estimation under star-shaped constraints, 2024. arXiv:2412.03832 [math.ST]. Under major revision at Annals of Statistics.\n\nA. Prasadan, D. A. James, and J. Greenhouse. Assessing CAR-T immunotherapy outcomes using multistate models, pharmacokinetics, and tumor burden. Novartis Technical Report, 2022.\n\nP. Sasan, A. Prasadan, and V. Q. Vu. Computationally sufficient reductions for some sparse multiway and joint matrix estimators, 2025. Submitted.\n\nM. T. Dresse, P. C. L. Ferreira, A. Prasadan, J. L. Diaz, X. Zeng, B. Bellaver, G. Povala, V. L. Villemagne, M. I. Kamboh, A. D. Cohen, T. A. Pascoal, M. Ganguli, B. E. Snitz, C. E. Shaaban, T. K. Karikari. Plasma biomarkers identify brain ATN abnormalities in a dementia-free population-based cohort, 2025. To appear in Alzheimer’s Research & Therapy."
  },
  {
    "objectID": "posts/2025-05-31-university-enrollment/index.html",
    "href": "posts/2025-05-31-university-enrollment/index.html",
    "title": "Make your title legendary",
    "section": "",
    "text": "I was recently browsing the excellent R Graph Gallery website and came across a gorgeous dumbbell plot made by Tobias Stalder for TidyTuesday.1 A dumbbell plot is a two-sided extension of a lollipop plot, which is in turn a substitute for the familiar but bland bar chart. The bar is replaced with a single line, and a point is added to the end. Tobias Stalder’s submission showed the large gap in university enrollment between men and women at Historically Black Colleges and Universities (HBCU). I especially liked his choice of using color in the subtitle rather than having a legend taking up unnecessary space.\n\n\n\n\n\nTobias Stalder’s TidyTuesday submission\n\n\n\n\nIn this post, I decided to find broader country-wide trends in university enrollments stratified by sex and make a similar plot. I visited the US government-ran Digest of Education Statistics website ran by The Institute of Education Sciences. In Chapter 3, under section 303 (Total Fall Enrollment — General), I accessed Table 303.10 to see fall enrollment in the US from 1947 to 2023. The data also includes the breakdown of public versus private as well as full-time versus part-time. For now, I decided to just plot the entire time series, so I won’t include the summary statistics in my plot that Tobias did (e.g., the mean is itself changing over time, so I’m not sure a global mean is very useful).\nBefore I dive in, let me summarize some of the important tidyverse skills this post covers:\n\nRead in Excel files with the readxl package, and ignoring extraneous rows/columns\nCleaning column names with the janitor package and its clean_names() function\nMaking dumbbells and lollipops with geom_segment()\nFeeding in multiple tibbles in your various ggplot geometries (and the inherit.aes argument)\nAdding transparent background images with geom_image() from the ggimage package\nAdding color and formatting to text in the titles/captions using the ggtext package\nChanging the font with the showtext package"
  },
  {
    "objectID": "posts/2025-05-31-university-enrollment/index.html#our-basic-geometries",
    "href": "posts/2025-05-31-university-enrollment/index.html#our-basic-geometries",
    "title": "Make your title legendary",
    "section": "Our basic Geometries",
    "text": "Our basic Geometries\nWe will start by adding points with year on the \\(x\\) axis and enrollment_pct on the \\(y\\) axis colored by sex. Then we add a segment from the male to female values using geom_segment(). To do so, we actually feed in the wide dataset df because it takes in a y and yend aesthetic for which we will specify prop_male and prop_female, respectively. The long version of the dataset no longer has these columns. However, the df dataframe does not have a sex column, so we don’t want to feed in the previous aesthetics. Thus, we must include an inherit.aes = F argument to geom_segment().\n\n\nCode\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point() +\n  geom_segment(\n    # Use df to access prop_male, prop_female\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    # df doesn't have a sex column\n    inherit.aes = F\n  ) \n\n\n\n\n\n\n\n\n\nThe next step is to add the vertical line for the transition point where more females than males enroll. We will feed in a new dataset again, the final_male_df row we saved. I want the line to occur on the first year in which female enrollment is higher, so I add one to the year. Once again, we’ll need to not inherit the aesthetics. The reason I used geom_segment() instead of geom_vline() is that I wanted finer control over where the line starts and ends.\n\n\nCode\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point() +\n  geom_segment(\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    inherit.aes = F\n  ) +\n  geom_segment(\n    # this is why we saved a 1 row tibble, not just the year\n    data = final_male_df,\n    aes(x = year + 1),\n    y = 0.25,\n    yend = 0.7,\n    inherit.aes = F\n  ) \n\n\n\n\n\n\n\n\n\nThe last geometry I wish to add is geom_image(). The plot is fairly bare, so I wanted a transparent graphic representing education sitting in the bottom right. We’ll have to load in the ggimage package. To add transparency, we copy the technique here and define a transparency function to pass into geom_image().\n\n\nCode\nlibrary(ggimage)\n\ntransparent &lt;- function(img) {\n  magick::image_fx(img, expression = \"0.5*a\", channel = \"alpha\")\n}\n\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point() +\n  geom_segment(\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    inherit.aes = F\n  ) +\n  geom_segment(\n    data = final_male_df,\n    aes(x = year + 1),\n    y = 0.25,\n    yend = 0.7,\n    inherit.aes = F\n  ) +\n  ggimage::geom_image(\n    # create a temp. tibble to pass in aesthetics\n    data = tibble(year = 1998, enrollment_pct = 0.32),\n    aes(x = year, y = enrollment_pct, \n        image = 'generic_students.png'),\n    image_fun = transparent,\n    size = 0.3,\n    inherit.aes = F\n  ) \n\n\n\n\n\n\n\n\n\nI’ll add in some styling to these geoms.\n\n\nCode\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point(size = 2.1) +\n  geom_segment(\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    inherit.aes = F,\n    alpha = 0.3,\n    linewidth = 2.2,\n    color = '#d95f02'\n  ) +\n  geom_segment(\n    data = final_male_df,\n    aes(x = year + 1),\n    y = 0.25,\n    yend = 0.7,\n    color = '#d95f02',\n    linewidth = 1,\n    alpha = 0.5,\n    linetype = 'dotdash',\n    inherit.aes = F\n  ) +\n  ggimage::geom_image(\n    data = tibble(year = 1998, enrollment_pct = 0.32),\n    aes(x = year, y = enrollment_pct, image = 'generic_students.png'),\n    image_fun = transparent,\n    size = 0.3,\n    inherit.aes = F\n  )"
  },
  {
    "objectID": "posts/2025-05-31-university-enrollment/index.html#colors-and-scales",
    "href": "posts/2025-05-31-university-enrollment/index.html#colors-and-scales",
    "title": "Make your title legendary",
    "section": "Colors and Scales",
    "text": "Colors and Scales\nAfter consulting Color Brewer 2.0, I settled on using #7570b3 for male and #1b9e77 for female. For the bars, I used a transparent version of #d95f02. Let’s create a manual color scale to use these instead. We will remove the legend by specifying guide = 'none'.\nAlong the way, we can specify the breaks for the \\(x\\) and \\(y\\) axes, and use percent_format() from the scales package to get nice percent signs. The expand = c(0, 0) argument removes the automatic space added to the axes, so we can customize the limits manually.\n\n\nCode\nlibrary(scales)\n\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point(size = 2.1) +\n  geom_segment(\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    inherit.aes = F,\n    alpha = 0.3,\n    linewidth = 2.2,\n    color = '#d95f02'\n  ) +\n  geom_segment(\n    data = final_male_df,\n    aes(x = year + 1),\n    y = 0.25,\n    yend = 0.7,\n    color = '#d95f02',\n    linewidth = 1,\n    alpha = 0.5,\n    linetype = 'dotdash',\n    inherit.aes = F\n  ) +\n  ggimage::geom_image(\n    data =\n      tibble(year = 1998, enrollment_pct = 0.32),\n    aes(x = year, y = enrollment_pct, image = 'generic_students.png'),\n    image_fun = transparent,\n    size = 0.3,\n    inherit.aes = F\n  ) +\n  scale_y_continuous(\n    labels = scales::percent_format(),\n    limits = c(0.25, 0.73),\n    expand = c(0, 0)\n  ) +\n  scale_x_continuous(\n    breaks = seq(1950, 2025, by = 10),\n    limits = c(1945, 2024),\n    expand = c(0, 0)\n  ) +\n  scale_color_manual(\n    breaks = c(\"male\", \"female\"),\n    values = c(\"#7570b3\", '#1b9e77'),\n    guide = 'none'\n  ) \n\n\n\n\n\n\n\n\n\nLooks good. Let’s fix up the labels. Importantly, I want to put the legend in the title itself. To do that, we use the ggtext package and add the HTML tags in the title. To render it properly, we must call plot.title = element_markdown() inside the theme() function. The HTML format is messy, but goes like this: &lt;span style = 'color:{your-color};'&gt;{your-text}&lt;/span&gt;.\nThe same ggtext package lets me add line breaks to the caption as well, using &lt;br&gt;. We’ll reposition the caption using the plot.caption and plot.caption.position arguments.\n\n\nCode\nlibrary(ggtext)\n\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point(size = 2.1) +\n  geom_segment(\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    inherit.aes = F,\n    alpha = 0.3,\n    linewidth = 2.2,\n    color = '#d95f02'\n  ) +\n  geom_segment(\n    data = final_male_df,\n    aes(x = year + 1),\n    y = 0.25,\n    yend = 0.7,\n    color = '#d95f02',\n    linewidth = 1,\n    alpha = 0.5,\n    linetype = 'dotdash',\n    inherit.aes = F\n  ) +\n  ggimage::geom_image(\n    data = tibble(year = 1998, enrollment_pct = 0.32),\n    aes(x = year, y = enrollment_pct, image = 'generic_students.png'),\n    image_fun = transparent,\n    size = 0.3,\n    inherit.aes = F\n  ) +\n  scale_y_continuous(\n    labels = scales::percent_format(),\n    limits = c(0.25, 0.73),\n    expand = c(0, 0)\n  ) +\n  scale_x_continuous(\n    breaks = seq(1950, 2025, by = 10),\n    limits = c(1945, 2024),\n    expand = c(0, 0)\n  ) +\n  scale_color_manual(\n    breaks = c(\"male\", \"female\"),\n    values = c(\"#7570b3\", '#1b9e77'),\n    guide = 'none'\n  ) +\n  labs(\n    x = \"\",\n    y = \"\",\n    title = \"&lt;span style = 'color:#7570b3;'&gt;**Male**&lt;/span&gt; and &lt;span style = 'color:#1b9e77;'&gt;**Female**&lt;/span&gt; University Enrollment has swapped places.\",\n    subtitle = \"Proportion of Fall Enrollment between 1947 and 2023 (odd years only)\",\n    caption = \"Data sourced from *The Institute of Education Sciences*.&lt;br&gt;&lt;br&gt;Plot by Akshay Prasadan.\"\n  ) +\n  theme(\n    # use element_markdown() to tell ggtext to recognize the HTML\n    plot.title = ggtext::element_markdown(),\n    # Position caption on side of plot, not the graph panel\n    plot.caption.position = 'plot',\n    plot.caption = ggtext::element_markdown(hjust = 0) # move caption to left\n  )\n\n\n\n\n\n\n\n\n\nThe default theme looks ugly to me. Let’s remove the grey background, customize which panel gridlines we want, and make other minor changes. The easiest way to do this is to add theme_minimal() and then put back what is of interest.\n\n\nCode\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point(size = 2.1) +\n  geom_segment(\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    inherit.aes = F,\n    alpha = 0.3,\n    linewidth = 2.2,\n    color = '#d95f02'\n  ) +\n  geom_segment(\n    data = final_male_df,\n    aes(x = year + 1),\n    y = 0.25,\n    yend = 0.7,\n    color = '#d95f02',\n    linewidth = 1,\n    alpha = 0.5,\n    linetype = 'dotdash',\n    inherit.aes = F\n  ) +\n  ggimage::geom_image(\n    data = tibble(year = 1998, enrollment_pct = 0.32),\n    aes(x = year, y = enrollment_pct, image = 'generic_students.png'),\n    image_fun = transparent,\n    size = 0.3,\n    inherit.aes = F\n  ) +\n  scale_y_continuous(\n    labels = scales::percent_format(),\n    limits = c(0.25, 0.73),\n    expand = c(0, 0)\n  ) +\n  scale_x_continuous(\n    breaks = seq(1950, 2025, by = 10),\n    limits = c(1945, 2024),\n    expand = c(0, 0)\n  ) +\n  scale_color_manual(\n    breaks = c(\"male\", \"female\"),\n    values = c(\"#7570b3\", '#1b9e77'),\n    guide = 'none'\n  ) +\n  labs(\n    x = \"\",\n    y = \"\",\n    title = \"&lt;span style = 'color:#7570b3;'&gt;**Male**&lt;/span&gt; and &lt;span style = 'color:#1b9e77;'&gt;**Female**&lt;/span&gt; University Enrollment has swapped places.\",\n    subtitle = \"Proportion of Fall Enrollment between 1947 and 2023 (odd years only)\",\n    caption = \"Data sourced from *The Institute of Education Sciences*.&lt;br&gt;&lt;br&gt;Plot by Akshay Prasadan.\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    panel.grid.major.y = element_line(color = 'grey90', linetype = 'dotted'),\n    axis.ticks.x.bottom = element_line(color = 'black'),\n    axis.ticks.length.x.bottom = unit(4, units = 'pt'),\n    axis.text.x.bottom = element_text(color = 'black'),\n    axis.text.y.left = element_text(color = 'black'),\n    plot.title = ggtext::element_markdown(),\n    plot.caption.position = 'plot',\n    plot.caption = ggtext::element_markdown(hjust = 0)\n  )"
  },
  {
    "objectID": "posts/2025-05-31-university-enrollment/index.html#fonts",
    "href": "posts/2025-05-31-university-enrollment/index.html#fonts",
    "title": "Make your title legendary",
    "section": "Fonts",
    "text": "Fonts\nFor our final customization, let’s change the font to “Lato” from Google Fonts using the showtext package. We’ll need to set the global size using text = element_text(family = 'Lato', size = 5), since often times the default sizes will be way too big or small. For some weird reason, text that gets modified by element_markdown() sometimes loses their spaces, so to fix that, I added family = \"\" in the plot.caption= element_markdown() argument.\n\n\nCode\nlibrary(showtext)\n\n# sysfonts is loaded in by the showtext package\nsysfonts::font_add_google(\"Lato\")\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi = 300)\n\nlong_df |&gt;\n  ggplot(aes(x = year, y = enrollment_pct, color = sex)) +\n  geom_point(size = 2.1) +\n  geom_segment(\n    data = df,\n    aes(x = year, y = prop_male, yend = prop_female),\n    inherit.aes = F,\n    alpha = 0.3,\n    linewidth = 2.2,\n    color = '#d95f02'\n  ) +\n  geom_segment(\n    data = final_male_df,\n    aes(x = year + 1),\n    y = 0.25,\n    yend = 0.7,\n    color = '#d95f02',\n    linewidth = 1,\n    alpha = 0.5,\n    linetype = 'dotdash',\n    inherit.aes = F\n  ) +\n  ggimage::geom_image(\n    data = tibble(year = 1998, enrollment_pct = 0.32),\n    aes(x = year, y = enrollment_pct, image = 'generic_students.png'),\n    image_fun = transparent,\n    size = 0.3,\n    inherit.aes = F\n  ) +\n  scale_y_continuous(\n    labels = scales::percent_format(),\n    limits = c(0.25, 0.73),\n    expand = c(0, 0)\n  ) +\n  scale_x_continuous(\n    breaks = seq(1950, 2025, by = 10),\n    limits = c(1945, 2024),\n    expand = c(0, 0)\n  ) +\n  scale_color_manual(\n    breaks = c(\"male\", \"female\"),\n    values = c(\"#7570b3\", '#1b9e77'),\n    guide = 'none'\n  ) +\n  labs(\n    x = \"\",\n    y = \"\",\n    title = \"&lt;span style = 'color:#7570b3;'&gt;**Male**&lt;/span&gt; and &lt;span style = 'color:#1b9e77;'&gt;**Female**&lt;/span&gt; University Enrollment has swapped places.\",\n    subtitle = \"Proportion of Fall Enrollment between 1947 and 2023 (odd years only)\",\n    caption = \"Data sourced from *The Institute of Education Sciences*.&lt;br&gt;&lt;br&gt;Plot by Akshay Prasadan.\"\n  ) +\n  theme_minimal() +\n  theme(\n    # specify a global font size as a default\n    text = element_text(family = 'Lato', size = 7),\n    panel.grid = element_blank(),\n    panel.grid.major.y =\n      element_line(color = 'grey90', linetype = 'dotted'),\n    axis.ticks.x.bottom = element_line(color = 'black'),\n    axis.ticks.length.x.bottom = unit(4, units = 'pt'),\n    axis.text.x.bottom = element_text(color = 'black'),\n    axis.text.y.left = element_text(color = 'black'),\n    plot.title = ggtext::element_markdown(),\n    plot.caption.position = 'plot',\n    # add family = \"\" for some annoying bug with spaces\n    plot.caption = ggtext::element_markdown(hjust = 0, family = \"\")\n  )\n\n\n\n\n\nOur final version of the plot."
  },
  {
    "objectID": "posts/2025-05-31-university-enrollment/index.html#footnotes",
    "href": "posts/2025-05-31-university-enrollment/index.html#footnotes",
    "title": "Make your title legendary",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTidyTuesday is a weekly community ‘event’ (and podcast) in which data enthusiasts around the world share their data cleaning, visualizations and modelling techniques for that week’s data release.↩︎"
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html",
    "title": "First Impressions in Data Science Matter",
    "section": "",
    "text": "I was recently watching a talk by David Keyes from the Posit 2024 conference on the design of data science reports. He made a point that increasingly resonates with me: design matters. As data scientists, we don’t produce graphics, tables, papers, or Beamer presentations just for ourselves. We do so to persuade others. As Keyes’ explains, putting effort into design makes people perceive your work as both useful and trustworthy.\nIt is unfortunate, therefore, when important work in data science is presented with minimal care. Numbers aren’t formatted. Plots barely improve on the defaults. Font sizes are unreadable. Tables look like they were made in Google Docs in 30 seconds. I am definitely guilty of this in my past work. Now I’m trying to persuade fellow academics, journals, private companies, or even the government of the importance of my work. Design matters for this.\nThankfully, modern data science tools make it near effortless to level up the professional appearance of your work. Even the defaults have dramatically improved in appearance—compare the default base R scatterplot (Figure 1) to a typical ggplot. But we can do better.\nThis post highlights some simple fixes to level up your design while preserving reproducibility. I’m going to focus on topics that arise when dealing with Quarto or RMarkdown documents and presentations, but the concepts should be universal."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#use-great-tables-gt",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#use-great-tables-gt",
    "title": "First Impressions in Data Science Matter",
    "section": "Use Great Tables (gt)",
    "text": "Use Great Tables (gt)\nWhat makes ggplot so useful, in my opinion, is the ease of its grammar. You start with a basic ggplot, add on geometries, give those geometries aesthetics, modify the scales of those aesthetics, and then add on the various bells and whistles.\nThe gt package brought that grammar for tables instead of plots. Instead of the dull, default tables that R spits out like the following:\n\n\n\n\n\nenergy_type\namount\npercent\n\n\n\n\nCoal\n10450\n0.3520889\n\n\nGas\n6680\n0.2250674\n\n\nHydro\n4230\n0.1425202\n\n\nNuclear\n2700\n0.0909704\n\n\nWind\n2310\n0.0778302\n\n\nSolar\n1660\n0.0559299\n\n\nOil\n870\n0.0293127\n\n\nBioenergy\n690\n0.0232480\n\n\nOther\n90\n0.0030323\n\n\n\n\n\nwe can now create gorgeous tables full of color, logos, Markdown formatting, with an intuitive language. Rather than wrangling with a tibble() until you get the data in the form you want, let gt do that work for you.\n\n\n\n\n\n\n\n\nGlobal Electricity Production by Source\n\n\nData sourced from Our World in Data\n\n\n\nEnergy Source\nTWh (2023)\n% of Total\nCO₂ Intensity\n\n\n\n\n🪨\nCoal\n10,450\n35%\n\n\n\n🧯\nGas\n6,680\n23%\n\n\n\n💧\nHydro\n4,230\n14%\n\n\n\n☢️\nNuclear\n2,700\n9%\n\n\n\n🌬️\nWind\n2,310\n8%\n\n\n\n☀️\nSolar\n1,660\n6%\n\n\n\n🛢️\nOil\n870\n3%\n\n\n\n🪵\nBioenergy\n690\n2%\n\n\n\n🔶\nOther\n90\n0%\n\n\n\n\n\n\n\n\nIn a nutshell, the syntax is of the following form:\ndf |&gt;\n  # optional: group_by before this step\n  gt() |&gt; \n  # modify column attributes\n  cols_*() |&gt; \n  # format columns\n  fmt_*() |&gt; \n  # Labels\n  tab_*() \n  # for niche styling\n  opt_stylize()\nCheck out the various tutorials for the gt package on YouTube or the official documentation. Another useful package is gtsummary if you wish to quickly generate professional looking descriptive tables for scientific journals."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#rounding",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#rounding",
    "title": "First Impressions in Data Science Matter",
    "section": "Rounding",
    "text": "Rounding\nHard-coding numbers is the enemy of reproducibility. If you use code to compute some quantity, say a predicted temperature, you should not include it in your report by literally writing “We predict a temperature of 23.4 degrees Celsius.” What if you find a bug in your code? Then the intended temperature changes but your text does not.\nIn RMarkdown or Quarto, we can easily embed numbers using inline R (or Python) code. Assume you saved the value as a variable, say temp_pred, we simply write `r temp_pred` in the text portion of the document. Unfortunately, if you do this, the knitted report will display an ugly, unrounded decimal, like 23.420484762. Unless you’re a physicist at CERN, you probably don’t need temperatures this precise. Instead, write `r round(temp_pred, 2)` and show us a level of precision that is reasonable. If you prefer, you can also specify significant digits with signif."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#change-up-the-font",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#change-up-the-font",
    "title": "First Impressions in Data Science Matter",
    "section": "Change up the font",
    "text": "Change up the font\nWe’re all tired of the default Times New Roman or Computer Modern. There are enormous catalogues out there of different fonts, and you can use them in both PDF or HTML reports. In a PDF document made with Quarto, for example, you can adjust the mainfont argument in your Quarto front matter. You may have to install the fonts though, and this could make your documents harder for others to use.\nYou can also easily change the fonts of your ggplot plots within your document (see below)."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#use-human-language-not-computer-code-in-your-labels",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#use-human-language-not-computer-code-in-your-labels",
    "title": "First Impressions in Data Science Matter",
    "section": "Use human language, not computer code in your labels",
    "text": "Use human language, not computer code in your labels\nLeaving in \\(y\\)-axis labels like “temp,” or even worse, “predicted_temp” or “df$predicted_temp” tells the reader you did the absolute minimum to generate your plot. Anyone who took the time to actually edit the label would have written it nicely, so the fact you did not tells the reader about your indifference.\n\n\n\n\n\n\n\n\nFigure 1: Please forgive me for some base R."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#dont-overlabel",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#dont-overlabel",
    "title": "First Impressions in Data Science Matter",
    "section": "Don’t overlabel",
    "text": "Don’t overlabel\nThe reader does not need their intelligence insulted: “2004, 2005, …” on the x-axis does not warrant a “Year” label. In school, students are instructed to label their plots or face point deductions, and I believe this causes an over-reaction where plots are labelled to excess. In a similar vein, avoid redundant information in the title and axes. For example, if your plot title is “Median Energy Consumption by City in the US”, your \\(y\\)-axis does not need to state “Median Energy Consumption (kWh)” but something more succinct like “Consumption (kWh)” or even just the units (kWh).\nInstead take advantage of the opportunity to reduce the amount of text on your plot. Enjoy the minimalism of a blank space instead. Granted, if the application is particularly esoteric, it is better to err on the side of over-labelling."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#remove-the-default-theme",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#remove-the-default-theme",
    "title": "First Impressions in Data Science Matter",
    "section": "Remove the default theme",
    "text": "Remove the default theme\nThe gray background ggplot uses gets tiring quickly. The first thing I do when creating any plot is to add theme_light() or theme_bw(). This immediately cleans up your plot of distracting elements and lets you customize with your own colors. Even better, design your own personal theme and branding."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#change-the-colors.",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#change-the-colors.",
    "title": "First Impressions in Data Science Matter",
    "section": "Change the colors.",
    "text": "Change the colors.\nWhen I first learned about ggplot, I was amazed at how sleek the default plots look. But we can do better and generate our own palettes! There are some great tools out there, such as ColorBrewer 2.0 that can produce color palettes based on the type of data while also accounting for colorblindness or printability.\nBut don’t just arbitrarily pick some palette and call it a day. Think about the application of your data. Below I used an example of a plot I made for a class on data visualization. The left-side is default colors, and the right was my choice. The colors on the left mean absolutely nothing. Why is beer red and wine blue? Forget aesthetics: readers will struggle to remember what means what as their eyes scan the bars. On the right, the bars evoke a sense that you are really looking at a glass of IPA or red wine. Admittedly, I was unable to think of a compelling color for ‘spirits’, but blue does remind me of the vivid color of Bombay Sapphire.\n\n\n\n\n\nBland attempt\n\n\n\n\n\n\n\nHues that give you a Buzz\n\n\n\n\nHowever, it is important to not go overboard with colors. Stick to a palette throughout a report. Indeed, my ‘good’ example above is rather jarring to look at given this blog’s theme."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#fonts",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#fonts",
    "title": "First Impressions in Data Science Matter",
    "section": "Fonts",
    "text": "Fonts\nI highly recommend switching out the fonts in your title, axis labels, legends, and more. This is easy to do with the showtext package. Below I include a code snippet to set the font globally with a font of your choice from Google Fonts. You can also use different font families for different components of your plot, but I wouldn’t recommend it.\n\nlibrary(showtext)\n\n# robo is just a user-defined name you can invoke in your plotting functions\nfont_add_google(\"Roboto\", \"robo\")\n\n# To globally use this font\nshowtext_auto()"
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#use-high-resolution-figures",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#use-high-resolution-figures",
    "title": "First Impressions in Data Science Matter",
    "section": "Use High Resolution Figures",
    "text": "Use High Resolution Figures\nIf you’re displaying your ggplot figures in a report or presentation, remember that we are going to zoom in and note every little blemish. You’re creating a professional document, so don’t include images that might as well have been screenshots off your cell-phone.\nSave your plots with ggsave to the desired size and increase the dpi argument to 300 or more. You can also save objects as PDFs or SVG files to avoid the blurriness from zooming in (no dpi argument here).\nIf you changed the fonts with the showtext package, you may have to also specify showtext_opts(dpi = ...) so that your fonts are also of high resolution."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#make-your-fonts-comically-large",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#make-your-fonts-comically-large",
    "title": "First Impressions in Data Science Matter",
    "section": "Make your Fonts Comically Large",
    "text": "Make your Fonts Comically Large\nComically. It should make you cringe to look at on your computer. A large chunk of talks I’ve attended over the years use miniscule font sizes on plot labels, math equations, figure captions, etc. A presentation is not the same thing as a report. The audience can’t just zoom in like a PDF or web page. What looks fine on the computer is probably too small on the projector.\nI was a teaching assistant one year for a summer program on undergraduate research. Nearly every student made this same font mistake. So prior to their final presentations, I would often walk the students with me to the back of the class and asked them to read their own slides. That got the point across.\nSo go overboard, I say. Make the text on everything large enough that it makes you cringe. You will likely pre-empt some questions from people who missed critical points hidden in ant-sized text but were too polite to interrupt. Unless your goal is to hide that content from the audience, in which case, why even include it?\nSimilarly, resist the temptation to reduce font sizes just for the purpose of adding more content. Beamer does a decent job of using default sizes appropriate for presentations, but I prefer larger."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#beamer-remove-the-navigation-bar",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#beamer-remove-the-navigation-bar",
    "title": "First Impressions in Data Science Matter",
    "section": "Beamer: Remove the navigation bar",
    "text": "Beamer: Remove the navigation bar\nIn a default Beamer presentation made in LaTeX (or Quarto), one can find in the bottom margins a series of navigation buttons.\n\n\n\nDefault navigation buttons\n\n\nThese are, in my opinion, distracting, and completely pointless. It’s unclear what the second pair of buttons does (and what if the presentation doesn’t even have sections?). In your LaTeX or Quarto preamble (in the TeX section) you can just add \\setbeamertemplate{navigation symbols}{}."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#make-the-page-numbering-bigger",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#make-the-page-numbering-bigger",
    "title": "First Impressions in Data Science Matter",
    "section": "Make the page numbering bigger",
    "text": "Make the page numbering bigger\nAudience members like to refer back to page numbers with questions, so help them out by enlarging their size. Make sure the page numbers are the actual ‘frames’, i.e., the set of slides with the same content (hidden until the transition). Otherwise if you add bullet by bullet points, your slide numbers will be unnecessarily large."
  },
  {
    "objectID": "posts/2025-05-25-data-viz-pet-peeves/index.html#transitions-should-still-give-audience-members-time-to-read",
    "href": "posts/2025-05-25-data-viz-pet-peeves/index.html#transitions-should-still-give-audience-members-time-to-read",
    "title": "First Impressions in Data Science Matter",
    "section": "Transitions should still give audience members time to read",
    "text": "Transitions should still give audience members time to read\nOften times a speaker will include transitions for every bullet point. This is fine, I think, except when the speaker shows the last few points and immediately proceeds to the next slide without giving the audience the time to even read it. It is better to reveal points in batches or at least pause for a moment."
  },
  {
    "objectID": "industry.html",
    "href": "industry.html",
    "title": "Industry Experience",
    "section": "",
    "text": "See Multistate and Joint Models for details about my 2 years of collaboration (Jan. 2021 through May 2022, then Spring 2025) with Novartis statisticians to model the efficacy of a cutting edge blood cancer immunotherapy using multistate and joint models.\n\n\n\nA. Prasadan, D. A. James, and J. Greenhouse. Assessing CAR-T immunotherapy outcomes using multistate models, pharmacokinetics, and tumor burden. Novartis Technical Report, 2022.\n\nInvited Topics Contributed Session, Joint Statistical Meetings (JSM), Toronto, 2023. Joint modeling of transduced cellular kinetics, tumor size, and survival endpoints."
  },
  {
    "objectID": "industry.html#novartis-phd-fellow",
    "href": "industry.html#novartis-phd-fellow",
    "title": "Industry Experience",
    "section": "",
    "text": "See Multistate and Joint Models for details about my 2 years of collaboration (Jan. 2021 through May 2022, then Spring 2025) with Novartis statisticians to model the efficacy of a cutting edge blood cancer immunotherapy using multistate and joint models.\n\n\n\nA. Prasadan, D. A. James, and J. Greenhouse. Assessing CAR-T immunotherapy outcomes using multistate models, pharmacokinetics, and tumor burden. Novartis Technical Report, 2022.\n\nInvited Topics Contributed Session, Joint Statistical Meetings (JSM), Toronto, 2023. Joint modeling of transduced cellular kinetics, tumor size, and survival endpoints."
  },
  {
    "objectID": "industry.html#statistician-at-upmc",
    "href": "industry.html#statistician-at-upmc",
    "title": "Industry Experience",
    "section": "Statistician at UPMC",
    "text": "Statistician at UPMC\nAt the Karikari Laboratory headed by Dr. Thomas K. Karikari, clinicians are studying the use of biomarkers in the blood as diagnostic tools for Alzheimer’s Disease (AD). These biomarkers offer a more cost-effective and less invasive way to evaluate large populations for AD. While existing studies tend to sample from economically privileged populations, this study followed a socioeconomically disadvantaged cohort to broaden our understanding of the disease. I was one of a few statisticians helping design and implement statistical methods to explore this rich clinical data. I worked at the lab from 2024 through Summer 2025.\n\nFeatured Work\n\nM. T. Dresse, P. C. L. Ferreira, A. Prasadan, J. L. Diaz, X. Zeng, B. Bellaver, G. Povala, V. L. Villemagne, M. I. Kamboh, A. D. Cohen, T. A. Pascoal, M. Ganguli, B. E. Snitz, C. E. Shaaban, T. K. Karikari. Plasma biomarkers identify brain ATN abnormalities in a dementia-free population-based cohort, 2025. To appear in Alzheimer’s Research & Therapy."
  },
  {
    "objectID": "industry.html#data-science-intern-at-highmark-health",
    "href": "industry.html#data-science-intern-at-highmark-health",
    "title": "Industry Experience",
    "section": "Data Science Intern at Highmark Health",
    "text": "Data Science Intern at Highmark Health\nIn the summer of 2022, I implemented a bi-level linear programming algorithm recently developed by a CMU PhD. The goal is to devise a health insurance network that can optimize patient utility while simultaneously minimizing costs."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Akshay Prasadan",
    "section": "",
    "text": "Welcome! My name is Akshay and I’m an incoming Postdoctoral Fellow at Simon Fraser University (SFU) in Vancouver, Canada. I recently obtained my PhD in Statistics & Data Science from Carnegie Mellon University (CMU) in Pittsburgh, PA, which is where I also grew up. I have an undergraduate degree in Mathematics and Economics from The Ohio State University.\nAt SFU, I will be working on stochastic inverse problems applied to physical process models (more details to come). My PhD thesis was about minimax optimal shape-constrained mean estimation, with extensions for sub-Gaussian noise, adversarial contamination, and non-parametric regression settings. During my PhD, I additionally applied survival analysis techniques (multistate and joint models) to cancer immunotherapy data, as part of a CMU-Novartis collaboration. I was also a statistician for 1.5 years at the Karikari Lab at UPMC, where researchers are exploring the use of blood-based biomarkers as diagnostic tools for Alzheimer’s Disease. For more details, check out the Research and Industry pages.\nMy non-statistical hobbies include researching individual (value) stocks as well as video games—playing Escape from Tarkov and spectating competitive Advance Wars by Web matches. I also have a Blog for some opinions and tutorials on data visualization."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Just One More Plot",
    "section": "",
    "text": "Auto Pollution? I’m tired and exhausted of it!\n\n\n\nenvironment\n\n\nggplot\n\n\n\nProgress or stagnation in average vehicle emissions in the US.\n\n\n\nAkshay Prasadan\n\n\nJun 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMake your title legendary\n\n\n\nR\n\n\ndplyr\n\n\nggplot\n\n\n\nThe bells and whistles of a dumbbell plot on trends in university enrollment.\n\n\n\nAkshay Prasadan\n\n\nMay 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s Get in the Newspaper\n\n\n\nR\n\n\ndplyr\n\n\nggplot\n\n\n\nLearn from the best by replicating a New York Times graphic on America’s educational decline.\n\n\n\nAkshay Prasadan\n\n\nMay 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Impressions in Data Science Matter\n\n\n\nR\n\n\nggplot\n\n\nRMarkdown\n\n\nQuarto\n\n\n\nModern data science libraries make professional presentation effortless. Let’s tackle my biggest pet peeves.\n\n\n\nAkshay Prasadan\n\n\nMay 25, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-05-26-pandemic-math-replication/index.html",
    "href": "posts/2025-05-26-pandemic-math-replication/index.html",
    "title": "Let’s Get in the Newspaper",
    "section": "",
    "text": "Introduction\nA really valuable exercise in learning about data visualization with ggplot is finding high quality graphics found in popular newspapers or research agencies and attempting to recreate them from scratch. I was inspired by Dr. Patrick Schloss at the University of Michigan doing the same on his Riffomonas Project YouTube channel, and as my second blog post, wanted to contribute my own example. I hope to give those new to ggplot the confidence to create publication-worthy graphics, and what better way to start than by mimicking the experts from the newspaper.\nI decided to replicate a graph from a New York Times article on the decline of math and reading scores in the United States, among 8th and 4th graders, respectively. Below I display the graphic, produced by Francesca Paris using data from the National Assessment of Educational Progress (NAEP).\n\n\n\nNYT Graphic\n\n\nThe structure of this document is as follows. I’m going to start with a basic attempt, and then in several steps, ramp up the complexity until we get a plot that is nearly identical to the original graphic. At each step, I’m going to show you the code, with comments highlighting the main additions relative to the prior version. If you just want the entire code in one place and without my comments, skip to the very end. You can also click the “Show All Code” or “Hide All Code” button in the top right of this page if you have a preference.\n\n\nGetting Started\nI have obtained the data from the NAEP, but it wasn’t in a tidy form. I did some data cleaning and saved it as a clean .csv file you can access from this URL or by downloading it from my GitHub. Since this post isn’t about data wrangling but data visualization, I will spare you the details.\nProceeding to our first visual, we see that our tibble has columns Year, percentile (10, 25, 50, 75, or 90), score, and subject. We will use the geom_line() and geom_point() geometries, with aesthetics x = Year, y = score, and group = percentile, and lastly we facet by subject (i.e., a separate plot per value of subject). Well, let’s pause for a moment. We could facet by subject, but I realized later when creating this post that we lose the ability to easily set \\(y\\)-limits for each faceted panel separately. Instead, we will create two separate plot and put them together using the cowplot package. For now, let us just focus on the subject = math plot, since the code is the same. While we’re loading in packages, I’m going to import the Libre Franklin font from Google Fonts as that resembles the font used by the New York Times. We’ll actually change the fonts at the end.\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggtext) # Formats markdown in plot text\nlibrary(glue) # String interpolation\nlibrary(showtext) # Changing plot font\nlibrary(cowplot) # Combining ggplots in a grid\n\nfont_add_google(name = 'Libre Franklin', family = 'franklin')\n\n# Access on Github\nfilename = 'national_math_8th_reading_4th_scores_1990_to_2024_by_percentile.csv'\n\ndf = read_csv(filename) |&gt; \n  filter(Year &gt;= 2000) |&gt; \n  # focus on math for now\n  filter(subject == 'math')\n\nplot = df |&gt; \n  ggplot(aes(x = Year, \n             y = score,\n             group = percentile # one line per percentile\n  )) + \n  geom_point() + \n  geom_line() \n\nplot\n\n\n\n\n\nA basic first attempt.\n\n\n\n\nAlready, we have made a great start! Let’s take care of some low hanging fruit. We don’t need the \\(x\\)-axis label, and the \\(y\\)-axis label information will be present in the title. The title will be formatted with markdown using the ggtext package.\nLet’s reduce the unnecessary theme elements by adding theme_minimal(), including the grey background. Then we will remove the vertical grid-lines and the minor horizontal ones using the panel.grid.* arguments to theme(). We will also add back tick marks which were removed by theme_minimal().\n\n\nCode\nplot = df |&gt; \n  ggplot(aes(x = Year, \n             y = score, \n             group = percentile)) + \n  geom_point() + \n  geom_line() + \n  # Unnecessary theme-ing removed\n  theme_minimal() +\n  labs(x = NULL, \n       y = NULL,\n       title = \"**Math** scores for **8th graders**\") +\n  theme(# format facet labels with markdown\n        plot.title = element_markdown(),  \n        # Now remove a bunch of grid-lines\n        panel.grid.major.x = element_blank(), \n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        # add back x axis ticks and change their length\n        axis.ticks.x.bottom = element_line(),\n        axis.ticks.length.x.bottom = unit(0.2, \"cm\"))\n\nplot\n\n\n\n\n\nCleaning up the background, grid lines, and ticks.\n\n\n\n\nNext we need to add some color. The author chose to place the lowest and highest deciles in a different color than the rest. Thus, we will create a binary indicator column reflecting this grouping, prior to our ggplot. After that, we can add a color aesthetic according to this grouping. Using the ‘Eyedropper’ tool in Mozilla Firefox, I determined the author used colors ‘#b35f57’ and ‘#aaaaaa’. We will use scale_color_manual() to implement this new color scale. The legend is unnecessary, so we remove it using guides().\n\n\nCode\nplot = df |&gt; \n  mutate(is_extreme_score = \n           ifelse(percentile == '10' | percentile == '90',\n                  \"yes\", \"no\")) |&gt; \n  ggplot(aes(x = Year,\n             y = score, \n             group = percentile,\n             color = is_extreme_score)) + \n  geom_point() + \n  geom_line() + \n  theme_minimal() +\n  labs(x = NULL, \n       y = NULL,\n       title = \"**Math** scores for **8th graders**\") +\n  theme(plot.title = element_markdown(),  \n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        axis.ticks.x.bottom = element_line(),\n        axis.ticks.length.x.bottom = unit(0.2, \"cm\")) +\n  scale_color_manual(\n    # Specify breaks explicitly so we get colors in the right order\n    breaks = c('yes', 'no'), \n    values = c('#b35f57', '#aaaaaa')) +\n  guides(color = 'none') # unnecessary legend\n\nplot\n\n\n\n\n\nAdding color.\n\n\n\n\nWe now add the labels. This will require creating another column pretty_label in our dataset with the label. This will require some case-work with the case_when() function. Since we only want a label by the 2024 dot, we need to set the label as NA for all other years. The top and bottom percentiles have their own unique label, and for the middle percentiles, we can do some string interpolation using the glue package. After that, we can call the geom_richtext() function, which is an extension of geom_text() from the ggtext package to allow for Markdown formatting. In particular, we bold the extremes and add a line break with &lt;br&gt;. We also want the labels to the right, which we set using hjust.\n\n\nCode\nplot = df |&gt; \n  mutate(is_extreme_score = ifelse(percentile == '10' | percentile == '90',\n                                   \"yes\", \"no\"),\n         pretty_label = case_when(\n           percentile == 90 & Year == 2024 ~ \"**Top&lt;br&gt;scorers**\",\n           percentile == 10 & Year == 2024 ~ \"**Lowest&lt;br&gt; scorers**\",\n           (percentile &gt;= 25 | percentile &lt;= 90) & Year == 2024 ~ \n             glue(\"{percentile}th&lt;br&gt;percentile\"),\n           .default = NA_character_\n         )) |&gt; \n  ggplot(aes(x = Year,\n             y = score, \n             group = percentile,\n             color = is_extreme_score)) + \n  geom_point() + \n  geom_line() + \n  geom_richtext(aes(label = pretty_label),\n                fill = NA, # text box should be transparent\n                na.rm = TRUE, \n                label.color = NA, # Remove the box outline\n                hjust = 0 # re-position text to right\n                ) +\n  theme_minimal() +\n  labs(x = NULL, \n       y = NULL,\n       title = \"**Math** scores for **8th graders**\") +\n  theme(plot.title = element_markdown(),  \n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        axis.ticks.x.bottom = element_line(),\n        axis.ticks.length.x.bottom = unit(0.2, \"cm\")) +\n  scale_color_manual(breaks = c('yes', 'no'),\n                     values = c('#b35f57', '#aaaaaa')) +\n  guides(color = 'none') \n\nplot\n\n\n\n\n\nLabels with HTML/Markdown formatting.\n\n\n\n\nWe need to fix the limits, margins, and breaks of the axes. For example, we want to prevent plot items like the text from being clipped by the panel margins, and instead be clipped by the plot boundaries itself.To do so, set clip = F with the coord_cartesian() function. While we’re at it, we can set expand = F to avoid the unnecessary expansion ggplot adds by default to the scale. Instead, we manually set the \\(x\\) and \\(y\\) limits with the scale_*_continuous() functions. It was at this point I realized why facet_wrap would fail: I needed to manually set the axes limits for each faceted plot separately, since math and reading are on different scales. The solution is to just make two separate ggplot objects and combine with the cowplot package later.\nIn addition to changing the limits, we can control the exact axis ticks that appear and their labels using the breaks and label argument of the scale_x_continuous() function. This requires some tedious relabeling of the axes.\nEven after this, we still need more space though. So we will directly set the plot.margin argument to give more space to the right.\n\n\nCode\nplot = df |&gt; \n  mutate(is_extreme_score = ifelse(percentile == '10' | percentile == '90',\n                                   \"yes\", \"no\"),\n         pretty_label = case_when(\n           percentile == 90 & Year == 2024 ~ \"**Top&lt;br&gt;scorers**\",\n           percentile == 10 & Year == 2024 ~ \"**Lowest&lt;br&gt; scorers**\",\n           (percentile &gt;= 25 | percentile &lt;= 90) & Year == 2024 ~ \n             glue(\"{percentile}th&lt;br&gt;percentile\"),\n           .default = NA_character_\n         )) |&gt; \n  ggplot(aes(x = Year,\n             y = score, \n             group = percentile,\n             color = is_extreme_score)) + \n  geom_point() + \n  geom_line() + \n  geom_richtext(aes(label = pretty_label),\n                fill = NA, na.rm = TRUE, label.color = NA,\n                hjust = 0) +\n  theme_minimal() +\n  labs(x = NULL, \n       y = NULL,\n       title = \"**Math** scores for **8th graders**\") +\n  theme(plot.title = element_markdown(),  \n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        axis.ticks.x.bottom = element_line(),\n        axis.ticks.length.x.bottom = unit(0.2, \"cm\"),\n        plot.margin = margin(0.5,2,0.5,0.5, \"cm\") # Add space on right of plot\n        ) +\n  scale_color_manual(breaks = c('yes', 'no'),\n                     values = c('#b35f57', '#aaaaaa')) +\n  guides(color = 'none') +\n  coord_cartesian(expand = F, clip = 'off') +\n  scale_y_continuous(limits = c(210, 340), # Where to start and end the y axis\n                     breaks = seq(220, 320, by = 20) # Where to put tick marks\n                     # Note, no labels argument necessary because we literally\n                     # want to show the integer as the label\n  ) +\n  scale_x_continuous(\n    # where to start and end the x axis\n    limits = c(2000, 2024), \n    # where the tick marks belong\n    breaks = c(2000, 2003, 2007, 2011, 2015, 2019, 2024),\n    # what to label the tick marks that we picked using breaks\n    labels = c(\"'00\", \"'03\", \"'07\", \"'11\", \"'15\",\"'19\", \"'24\")\n  )\n\nplot\n\n\n\n\n\nFixing axis limits, clipping, and axis labels.\n\n\n\n\n\n\nHandling two plots at a time\nThis looks close to completion for the math version. Let’s now write a function plot_generator() that makes the math or reading version of the plot. The function will take in the original tibble with both subjects included as well as the desired subject and output the specified plot. The function first does the necessary filtering and creation of new columns. The filtering part is a bit complicated, since we want to insert the subject argument into a dplyr function. This requires so called ‘tidy evaluation’ using the !! injection operator function from the rlang package. After subsetting and mutating the tibble, the function returns the plot.\nThe only components of the plot that are unique to each subject are the arguments to scale_y_continuous() and the title, so we’ll define those conditional on the subject. After that, we can generate the combined plot by calling the function plot_generator() twice and then using the simple cowplot library syntax. We can add in the caption using the plot_annotation() function.\n\n\nCode\nplot_generator = function(df, subject) {\n  if (subject == 'math') {\n    plot_title = \"**Math** scores for **8th graders**\"\n    y_limits = c(210, 340)\n    y_breaks = seq(220, 320, by = 20)\n  }\n  else if (subject == 'reading') {\n    plot_title = \"**Reading** scores for **4th graders**\"\n    y_limits = c(150, 270)\n    y_breaks = seq(160, 260, by = 20)\n  }\n  else(\n    stop(\"Pass in either 'math' or 'reading' as an argument for subject.\")\n  )\n  \n  df_subset = df |&gt; filter(Year &gt;= 2000) |&gt;\n    # Tricky note: Use rlang syntax for tidy evaluation  \n    filter(subject == !!subject) |&gt; \n    mutate(\n      is_extreme_score = ifelse(percentile == '10' | percentile == '90', \"yes\", \"no\"),\n      pretty_label = case_when(\n        percentile == 90 & Year == 2024 ~ \"**Top&lt;br&gt;scorers**\",\n        percentile == 10 &\n          Year == 2024 ~ \"**Lowest&lt;br&gt; scorers**\",\n        (percentile &gt;= 25 | percentile &lt;= 90) & Year == 2024 ~\n          glue(\"{percentile}th&lt;br&gt;percentile\"),\n        .default = NA_character_\n      )\n    ) \n  \n  plot = df_subset |&gt; ggplot(aes(\n    x = Year,\n    y = score,\n    group = percentile,\n    color = is_extreme_score\n  )) +\n    geom_point() +\n    geom_line() +\n    geom_richtext(\n      aes(label = pretty_label),\n      fill = NA,\n      na.rm = TRUE,\n      label.color = NA,\n      hjust = 0\n    ) +\n    theme_minimal() +\n    labs(x = NULL, y = NULL, title = plot_title) +\n    theme(\n      plot.title = element_markdown(),\n      panel.grid.major.x = element_blank(),\n      panel.grid.minor.x = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks.x.bottom = element_line(),\n      axis.ticks.length.x.bottom = unit(0.2, \"cm\"),\n      plot.margin = margin(0.5, 2, 0.5, 0.5, \"cm\")\n    ) +\n    scale_color_manual(breaks = c('yes', 'no'),\n                       values = c('#b35f57', '#aaaaaa')) +\n    guides(color = 'none') +\n    coord_cartesian(expand = F, clip = 'off') +\n    scale_y_continuous(limits = y_limits, breaks = y_breaks) +\n    scale_x_continuous(\n      limits = c(2000, 2024),\n      breaks = c(2000, 2003, 2007, 2011, 2015, 2019, 2024),\n      labels = c(\"'00\", \"'03\", \"'07\", \"'11\", \"'15\", \"'19\", \"'24\")\n    )\n  \n  return(plot)\n}\n\n\nNow let’s show a workflow to generate the plot. The placement of the individual plots in the cowplot can be modified using the draw_plot() arguments, which use relative scaling values (e.g., 0.15 means 15%). We can also add the caption with draw_label(). The caption also has a grey dot that I couldn’t replicate since the draw_label() function doesn’t support HTML customization (it is basically a wrapper for geom_label(), not something from the ggtext package). For similar reasons, I could not add the hyperlinks.\n\n\nCode\n# Access on GitHub (see beginning of post for link)\nfilename = 'national_math_8th_reading_4th_scores_1990_to_2024_by_percentile.csv'\ndf = read_csv(filename)\n\nplot_math = plot_generator(df, 'math')\nplot_reading = plot_generator(df, 'reading')\n\ncaption_text &lt;- paste(\n  \"Top scorers shown are at the 90th percentile; lowest scorers are at the 10th.\",\n  \"Scores are from the National Assessment of Educational Progress,\",\n  \"which tests a national sample of students to track educational achievement.\",\n  \"Source: NAEP. By Francesca Paris. Recreated by Akshay Prasadan.\",\n  sep = \"\\n\"\n)\n\n# Combine with cowplot\nplot &lt;- ggdraw() +\n  draw_plot(plot_math, x = 0, y = 0.10, width = 0.5, height = 0.85) +\n  draw_plot(plot_reading, x = 0.5, y = 0.10, width = 0.5, height = 0.85) +\n  draw_label(caption_text,\n             x = 0.03, y = 0.016, hjust = 0, vjust = 0,\n             size = 9, lineheight = 1.2,\n             fontfamily = 'franklin',\n             fontface = \"plain\", color = 'grey40')\n\nplot\n\n\n\n\n\nOur first combo plot.\n\n\n\n\nWow! That’s nearly perfect! It’s time for the final batch of editing. I find it easiest to first fix a size, and then save your plot using ggsave with those precise dimensions. Then, I fine-tune the margins or font sizes until it looks appropriate for that fixed dimension. If you rely on RStudio’s plotting window, then the sizes will vary depending on your zoom level or the size of the window on your monitor. This is not reproducible.\nRecall I imported the Libre Franklin font, which is an approximation of the NYT’s font for graphics. Now I’m going to actually apply that font. After that I will make several minor sizing tweaks. This part isn’t very interesting, but I’ll comment my main changes.\n\n\nCode\nshowtext_opts(dpi = 300)\nshowtext_auto()\n\nplot_generator_final = function(df, subject) {\n  if (subject == 'math') {\n    plot_title = \"**Math** scores for **8th graders**\"\n    y_limits = c(210, 340)\n    y_breaks = seq(220, 320, by = 20)\n  }\n  else if (subject == 'reading') {\n    plot_title = \"**Reading** scores for **4th graders**\"\n    y_limits = c(150, 270)\n    y_breaks = seq(160, 260, by = 20)\n  }\n  else(\n    stop(\"Pass in either 'math' or 'reading' as an argument for subject.\")\n  )\n  \n  df_subset = df |&gt; filter(Year &gt;= 2000) |&gt;\n    filter(subject == !!subject) |&gt; \n    mutate(\n      is_extreme_score = ifelse(percentile == '10' | \n                                  percentile == '90', \"yes\", \"no\"),\n      pretty_label = case_when(\n        percentile == 90 & Year == 2024 ~ \"**Top&lt;br&gt;scorers**\",\n        percentile == 10 &\n          Year == 2024 ~ \"**Lowest&lt;br&gt; scorers**\",\n        (percentile &gt;= 25 | percentile &lt;= 90) & Year == 2024 ~\n          glue(\"{percentile}th&lt;br&gt;percentile\"),\n        .default = NA_character_\n      )\n    ) \n  \n  plot = df_subset |&gt; ggplot(aes(\n    x = Year,\n    y = score,\n    group = percentile,\n    color = is_extreme_score\n  )) +\n    geom_point() +\n    geom_line() +\n    geom_richtext(\n      aes(label = pretty_label),\n      fill = NA,\n      na.rm = TRUE,\n      label.color = NA,\n      hjust = 0,\n      size = 4, # Make label font size close to title font (units are weird)\n      lineheight = 0.75 # Reduce line spacing of labels\n    ) +\n    theme_minimal() +\n    labs(x = NULL, \n         y = NULL, \n         title = plot_title) +\n    theme(\n      text = element_text(family = 'franklin'),\n      plot.title = element_textbox_simple(size = 12, \n                                          width= NULL, \n                                          # Prevent line break in titles\n                                          padding = margin(0,0,10,0)\n      ),\n      panel.grid.major.x = element_blank(),\n      panel.grid.minor.x = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks.x.bottom = element_line(),\n      axis.ticks.length.x.bottom = unit(0.2, \"cm\"),\n      plot.margin = margin(0, 2, 0.5, 0.5, \"cm\"),\n      # Refine axis tick label sizes, i.e., the \"'00\", \"'03\", etc.\n      axis.text.x = element_text(size = 8, family = 'franklin'),\n      axis.text.y = element_text(size = 8, hjust = 1,\n                                 margin = margin(0, 6, 0, 0)),\n      # Make sure plot title starts at plot edge (left-most boundary), \n      # not panel edge (panel = subset of plot)\n      plot.title.position = 'plot'\n    ) +\n    scale_color_manual(breaks = c('yes', 'no'),\n                       values = c('#b35f57', '#aaaaaa')) +\n    guides(color = 'none') +\n    coord_cartesian(expand = F, clip = 'off') +\n    scale_y_continuous(limits = y_limits, breaks = y_breaks) +\n    scale_x_continuous(\n      limits = c(2000, 2024),\n      breaks = c(2000, 2003, 2007, 2011, 2015, 2019, 2024),\n      labels = c(\"'00\", \"'03\", \"'07\", \"'11\", \"'15\", \"'19\", \"'24\")\n    )\n  \n  return(plot)\n}\n\n\nplot_math_final = plot_generator_final(df, 'math')\nplot_reading_final = plot_generator_final(df, 'reading')\n\nplot_final &lt;- ggdraw() +\n  draw_plot(plot_math_final, x = 0, y = 0.12, width = 0.5, height = 0.85) +\n  draw_plot(plot_reading_final, x = 0.5, y = 0.12, width = 0.5, height = 0.85) +\n  draw_label(caption_text,\n             x = 0.03, y = 0.015, hjust = 0, vjust = 0,\n             size = 9, lineheight = 1.2,\n             fontfamily = 'franklin', fontface = 'plain', color = 'grey40')\n\n# Save\nggsave(\"replicated_nyt.png\", plot_final, width = 6.6, height = 6.1, dpi = 300, bg = 'white')\n\n\n\n\n\nFinal version of replicated graphic.\n\n\nLooks pretty good, right? Let me repost below the original.\n\n\n\nOriginal NYT Graphic.\n\n\n\n\nFinal Remarks\nA careful inspection reveals many additional deficiencies in my replication attempt. For example, it seems the author actually used alpha as an aesthetic for the column we called is_extreme_score, since the percentiles seem to change transparency for the 25th, 50th, and 75th levels. The fonts seem a bit thicker too for the extremes. It would probably be easiest to just manually annotate the plot for finer font control. At this point, I feel like I’m giving up reproducibility, D.R.Y. code, and other programming tenets, but haven’t I turned from a programmer into a graphic designer at this point anyway?\nMoreover, I still do not fully understand the best way to fine-tune margins of the various plot objects, since practically every theme argument has its own margin argument. So the spacing certainly doesn’t match the original. At a certain point, I basically gave up out of frustration.\nBut this is an exercise in learning ggplot, not patience. My central goal was to prove that I, and more importantly, you, the reader, can build high quality graphics that belong in leading newspaper publications. Granted, all the credit goes to the New York Times and Francesca Paris for their original design. I look forward to some future exercises like this, perhaps with The Economist, Bloomberg, or Financial Times instead.\n\n\nThe complete code from start to finish\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggtext) \nlibrary(glue)\nlibrary(showtext) \nlibrary(cowplot) \n\nfont_add_google(name = 'Libre Franklin', family = 'franklin')\nshowtext_opts(dpi = 300)\nshowtext_auto()\n\nplot_generator_final = function(df, subject) {\n  if (subject == 'math') {\n    plot_title = \"**Math** scores for **8th graders**\"\n    y_limits = c(210, 340)\n    y_breaks = seq(220, 320, by = 20)\n  }\n  else if (subject == 'reading') {\n    plot_title = \"**Reading** scores for **4th graders**\"\n    y_limits = c(150, 270)\n    y_breaks = seq(160, 260, by = 20)\n  }\n  else(\n    stop(\"Pass in either 'math' or 'reading' as an argument for subject.\")\n  )\n  \n  df_subset = df |&gt; filter(Year &gt;= 2000) |&gt;\n    filter(subject == !!subject) |&gt; \n    mutate(\n      is_extreme_score = ifelse(percentile == '10' | \n                                  percentile == '90', \"yes\", \"no\"),\n      pretty_label = case_when(\n        percentile == 90 & Year == 2024 ~ \"**Top&lt;br&gt;scorers**\",\n        percentile == 10 &\n          Year == 2024 ~ \"**Lowest&lt;br&gt; scorers**\",\n        (percentile &gt;= 25 | percentile &lt;= 90) & Year == 2024 ~\n          glue(\"{percentile}th&lt;br&gt;percentile\"),\n        .default = NA_character_\n      )\n    ) \n  \n  plot = df_subset |&gt; ggplot(aes(\n    x = Year,\n    y = score,\n    group = percentile,\n    color = is_extreme_score\n  )) +\n    geom_point() +\n    geom_line() +\n    geom_richtext(\n      aes(label = pretty_label),\n      fill = NA,\n      na.rm = TRUE,\n      label.color = NA,\n      hjust = 0,\n      size = 4, \n      lineheight = 0.75 \n    ) +\n    theme_minimal() +\n    labs(x = NULL, \n         y = NULL, \n         title = plot_title) +\n    theme(\n      text = element_text(family = 'franklin'),\n      plot.title = element_textbox_simple(size = 12, \n                                          width = NULL, \n                                          padding = margin(0,0,10,0)\n      ),\n      panel.grid.major.x = element_blank(),\n      panel.grid.minor.x = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks.x.bottom = element_line(),\n      axis.ticks.length.x.bottom = unit(0.2, \"cm\"),\n      plot.margin = margin(0, 2, 0.5, 0.5, \"cm\"),\n      axis.text.x = element_text(size = 8, family = 'franklin'),\n      axis.text.y = element_text(size = 8, hjust = 1,\n                                 margin = margin(0, 6, 0, 0)),\n      plot.title.position = 'plot'\n    ) +\n    scale_color_manual(breaks = c('yes', 'no'),\n                       values = c('#b35f57', '#aaaaaa')) +\n    guides(color = 'none') +\n    coord_cartesian(expand = F, clip = 'off') +\n    scale_y_continuous(limits = y_limits, breaks = y_breaks) +\n    scale_x_continuous(\n      limits = c(2000, 2024),\n      breaks = c(2000, 2003, 2007, 2011, 2015, 2019, 2024),\n      labels = c(\"'00\", \"'03\", \"'07\", \"'11\", \"'15\", \"'19\", \"'24\")\n    )\n  \n  return(plot)\n}\n\nfilename = 'national_math_8th_reading_4th_scores_1990_to_2024_by_percentile.csv'\ndf = read_csv(filename) \n\ncaption_text &lt;- paste(\n  \"Top scorers shown are at the 90th percentile; lowest scorers are at the 10th.\",\n  \"Scores are from the National Assessment of Educational Progress,\",\n  \"which tests a national sample of students to track educational achievement.\",\n  \"Source: NAEP. By Francesca Paris. Recreated by Akshay Prasadan.\",\n  sep = \"\\n\"\n)\n\nplot_math_final = plot_generator_final(df, 'math')\nplot_reading_final = plot_generator_final(df, 'reading')\n\nplot &lt;- ggdraw() +\n  draw_plot(plot_math, x = 0, y = 0.10, width = 0.5, height = 0.85) +\n  draw_plot(plot_reading, x = 0.5, y = 0.10, width = 0.5, height = 0.85) +\n  draw_label(caption_text,\n             x = 0.03, y = 0.016, hjust = 0, vjust = 0,\n             size = 9, lineheight = 1.2,\n             fontfamily = 'franklin',\n             fontface = \"plain\", color = 'grey40')\n\nggsave(\"replicated_nyt.png\", plot_final, width = 6.6, height = 6.1, dpi = 300, bg = 'white')\n\n\n\n\n\n\n\n\nCitationFor attribution, please cite this work as:\nPrasadan, Akshay. 2025. “Let’s Get in the Newspaper.” May\n26, 2025. https://akprasadan.github.io/posts/2025-05-26-pandemic-math-replication/."
  },
  {
    "objectID": "posts/2025-06-07-vehicle-emissions/index.html",
    "href": "posts/2025-06-07-vehicle-emissions/index.html",
    "title": "Auto Pollution? I’m tired and exhausted of it!",
    "section": "",
    "text": "Few things make me more conscious about the environment and climate than my commute back from work in the summer. I am surrounded by impatient drivers piled up at intersections, heavy engines from nearby work trucks buzzing with vengeance and pumping foul fumes into the air. My discomfort is amplified by the oppressive heat and the barely functioning air-conditioning system of the 2009 sedan I drive. Unfortunately, I picture this when I think about summer, not blue skies, gentle breezes, and peaceful ocean waves.\nAll this has raised my curiosity about cars. Automobiles are incredible machines. Think about the complexity of an internal combustion engine. A heavy piece of steel called a piston creates a gap, drawing in air. A fuel injector sprays a precise quantity of gasoline into the chamber. The piston compresses the mixture, while an electrical source ignites the pressurized mixture, and the piston explodes downward, then back up to expel the spent fuel. This happens thousands of times a minute in a gasoline-fueled car and the engine somehow can handle this task for years with minimal maintenance. But what happens to the expelled combustion elements? It gets sent out the exhaust of your car as a mixture of carbon monoxide, carbon dioxide, methane, nitrogen oxides, and other assorted pollutants. Not only does this contribute to the greenhouse gases of our atmosphere, it worsens local air pollution and creates smog.\nThankfully, it turns out automobile manufacturers have made a lot of progress in reducing these pollutants, thanks in part to higher efficiency in converting chemical into mechanical energy as well as catalytic converters that capture certain pollutants. What more, now we have electric vehicles which nearly eliminate pollutants altogether. This is because combustion is replaced by the simple mechanism of electromagnetic fields generated from battery power directly spinning the wheel, without the added (and inefficient) complexity of having to convert the chemical energy of fossil fuels into the vertical motion of pistons and then into the rotation of the crankshaft.1\nIn this post, I take data provided on the Bureau of Transport Statistics website and sourced from the EPA to analyze trends in emissions (measured in grams per mile) from gasoline and diesel vehicles in the US. If, for example, the transition to EVs ends up slowing down, it would be comforting to see ICE vehicles reducing their emissions nonetheless. The data is broken down by vehicle and fuel type, but the EPA also computes average emissions across all vehicle/fuel types. This average takes into account the age distribution of the national fleet, regulatory changes, and typical driving behaviors like speed or idle time. Note that technological improvements in ICE engines will not immediately show up in the average car (which is several years old).\nThis won’t be a tutorial in ggplot like my previous posts, but I will use it to show off my ggplot skills nonetheless. The code and input data can be found on my GitHub repository. Moreover, I am not very familiar with cars, so a lot of my conclusions are speculative in nature. I’m sure I will make some embarrassing errors with auto technology, if I have not already."
  },
  {
    "objectID": "posts/2025-06-07-vehicle-emissions/index.html#footnotes",
    "href": "posts/2025-06-07-vehicle-emissions/index.html#footnotes",
    "title": "Auto Pollution? I’m tired and exhausted of it!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOf course, EVs that charge from a dirty electric grid contribute to emissions indirectly, and the environmental impact of the mining and processing of key metals for the battery should not be ignored. But I think these criticisms are often exaggerated for political purposes, and in the net, the transition to EVs from ICE vehicles will be a net positive for the world.↩︎"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "This page summarizes some of the recent research I worked on during my PhD with my advisor Matey Neykov, and continue to on the side as I transition toward my postdoctoral research. A full list of the resulting publications can be found on my Publications page. Soon I will add section on my postdoctoral research."
  },
  {
    "objectID": "research.html#shape-constrained-mean-estimation",
    "href": "research.html#shape-constrained-mean-estimation",
    "title": "Research",
    "section": "Shape-Constrained Mean Estimation",
    "text": "Shape-Constrained Mean Estimation\nThis topic was the subject of my thesis and combined several themes all at once: mean estimation, minimax optimality, shape-constraints, adversarial contamination, sub-Gaussian noise, and function classes. Let me give a brief overview.\nA fundamental problem in statistics is estimating some unknown signal \\(\\mu\\) (could be a real number, vector, or function). We are given several noisy observations of the form \\(Y_i=\\mu+\\xi_i\\) where \\(\\xi_i\\) is IID Gaussian noise. At this point, you might propose something like the average \\(\\overline{Y}_i\\) as our estimate of \\(\\mu\\).\nNext, suppose we are told that \\(\\mu\\) must belong to a known set \\(K\\). Has the problem become easier? No! Now, we must devise an algorithm that always returns an estimate in this set. This is called shape-constrained estimation.\nMoreover, we want an estimate that is minimax optimal. This is a very conservative but important benchmark for assessing the performance of an estimator. In this context, we want to produce an estimator whose average performance in the worst-case choice of \\(\\mu\\) is minimized. I said ‘average’ because there is randomness in the data generating process for \\(\\vec{Y}\\), and worst case because \\(\\mu\\) could, in principle, come from anywhere in \\(K\\). In the simple Euclidean vector case, this might be of the form: \\[\\inf_{\\hat{\\mu}} \\sup_{\\mu \\in K} \\mathbb{E}\\|\\hat{\\mu}(\\vec{Y}) - \\mu\\|_2^2,\\] where \\(\\hat\\mu\\) ranges over the set of all estimators evaluated on my random data \\(\\vec{Y}\\).\nIn this work, we devised minimax optimal techniques to estimate means when the underlying set was star-shaped (see below), a generalization of convexity. We extended this work to a non-parametric regression setting, i.e., observing \\(Y_i=f^{\\ast}(X_i)+\\xi_i\\) and trying to find \\(f^{\\ast}\\). We also allowed for adversarial contamination of some fraction \\(\\epsilon&lt;1/2\\) of the data. In each of these problems, we generalized our assumptions on \\(\\xi_i\\) to permit sub-Gaussian noise, which is a rich class of probability distributions whose tails are ‘lighter’ than Gaussians.\nThis thesis was ultimately one of many sequels to my advisor’s original 2022 paper which studied a convex-constrained mean estimation problem1. The framework continues to inspire work, including applications in heavy-tailed noise and density estimation with contamination.\n\n\n\nAn example of a star-shaped set, an unknown mean \\(\\mu\\), and a noisy observation \\(\\mu+\\xi\\). We say a set \\(K\\) is star-shaped if there exists a center \\(k^{\\ast} \\in K\\) such that for all \\(k \\in K\\) and \\(\\alpha \\in [0,1]\\), the point \\(\\alpha k + (1 - \\alpha) k^{\\ast}\\) also lies in \\(K\\). Here the literal center of the given shape functions as the ‘center’ in the star-shaped definition.\n\n\n\nFeatured Work\n\nA. Prasadan and M. Neykov. Characterizing the minimax rate of nonparametric regression under bounded star-shaped constraints, 2024. arXiv:2401.07968 [math.ST]. To appear in Electronic Journal of Statistics.\n\nA. Prasadan and M. Neykov. Some facts about the optimality of the LSE in the Gaussian sequence model with convex constraint, 2024. arXiv:2406.05911 [math.ST]. Submitted.\nA. Prasadan and M. Neykov. Information theoretic limits of robust sub-Gaussian mean estimation under star-shaped constraints, 2024. arXiv:2412.03832 [math.ST]. Under major revision at Annals of Statistics."
  },
  {
    "objectID": "research.html#multistate-and-joint-models",
    "href": "research.html#multistate-and-joint-models",
    "title": "Research",
    "section": "Multistate and Joint Models",
    "text": "Multistate and Joint Models\nDuring my PhD, I joined a collaboration between CMU and Novartis to study the use of flexible survival analysis techniques to model the efficacy of immunotherapy for blood cancers. The treatment itself sounds straight out of a sci-fi novel: scientists bioengineer immune cells to modify their own outer cell structure so the cells learn to attack cancer cells.\nClassic survival analysis can be used to model the literal survival of a subject: the subject is either alive or dead, for example. But what if we wish to capture the dynamic trajectory of patients through different stages of sickness? For example, the patient might first see their condition worsening, then improving, then becoming fully cancer-free or reverting to total treatment failure. A multi-state model allows us to model a patient’s transitions between different states (of cancer), and thus is a powerful tool for evaluating cancer treatments.\nThe second theme of this work was joint models, which are a lot more exciting than their generic name suggests. The idea is to jointly model longitudinal and survival processes, when the longitudinal data is endogenous, or internal to the patient. Classic Cox proportional hazard models can handle time varying covariates, but they require exogeneity. This means, for example, that if the patient is censored (e.g., leaves the study or dies), then the existence of the longitudinal covariate should be unaffected. This is true if, for example, your longitudinal variable is the weather. But clearly it fails with biomarkers in your blood. With a joint model, we compute a posterior distribution over the longitudinal and survival processes that gives theoretically valid estimates unlike the regular Cox proportional hazard model.\nI used this work to satisfy our PhD program’s requirement of completing an “Advanced Data Analysis” project. I worked with Joel Greenhouse at CMU as well as a team of statisticians at Novartis for about 2 years. I also presented some of our work on joint models at the 2023 Joint Statistical Meetings in Toronto.\n\nFeatured Work\n\nA. Prasadan, D. A. James, and J. Greenhouse. Assessing CAR-T immunotherapy outcomes using multistate models, pharmacokinetics, and tumor burden. Novartis Technical Report, 2022.\n\nInvited Topics Contributed Session, Joint Statistical Meetings (JSM), Toronto, 2023. Joint modeling of transduced cellular kinetics, tumor size, and survival endpoints."
  },
  {
    "objectID": "research.html#footnotes",
    "href": "research.html#footnotes",
    "title": "Research",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nM. Neykov, On the Minimax Rate of the Gaussian Sequence Model Under Bounded Convex Constraints, IEEE Transactions on Information Theory, vol. 69, no. 2, pp. 1244–1260, 2023. https://doi.org/10.1109/TIT.2022.3213141.↩︎"
  }
]